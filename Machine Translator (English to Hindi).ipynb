{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jump.\tउछलो.\n",
      "['\\ufeffHelp!', 'बचाओ!']\n"
     ]
    }
   ],
   "source": [
    "# Assign the data path.\n",
    "data_path = \"hin.txt\"\n",
    "\n",
    "# Read in the data.\n",
    "lines = io.open(data_path, encoding = \"utf-8\").read().split(\"\\n\")\n",
    "lines  = lines[:-1]\n",
    "print(lines[1])\n",
    "# Split the data into input and target sequences.\n",
    "lines = [line.split(\"\\t\") for line in lines]\n",
    "print(lines[0])\n",
    "# We define the starting signal to be \"\\t\" and the\n",
    "# ending signal to be \"\\n\". These signals tell the\n",
    "# model that when it sees \"\\t\" it should start\n",
    "# producing its translation and produce \"\\n\" when\n",
    "# it wants to end its translation. Let us add\n",
    "# \"\\t\" to the start and \"\\n\" to the end \n",
    "# of all input and output sentences.\n",
    "lines = [(\"\\t\" + line[0] + \"\\n\", \"\\t\" + line[1] + \"\\n\") for\n",
    "            line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tबचाओ!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (lines[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure out the Best Lengths of Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Sentence Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the input and output lengths.\n",
    "input_lengths = np.array([len(line[0]) for line in lines])\n",
    "output_lengths = np.array([len(line[1]) for line in lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870\n"
     ]
    }
   ],
   "source": [
    "print (len(input_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0, 80.0, 0.0, 120.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(input_lengths)\n",
    "plt.axis([75,80, 0 , 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.0, 89.0, 0.0, 20.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(output_lengths)\n",
    "plt.axis([85,89,0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = 78\n",
    "hindi = 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = []\n",
    "for i in range(len(input_lengths)):\n",
    "    if(input_lengths[i]<75 and output_lengths[i]<85):\n",
    "        line1 = line1 + [lines[i]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2857\n"
     ]
    }
   ],
   "source": [
    "print (len(line1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotted the histogram of the length of the input sentences and choose the length that makes the most sense. \n",
    "\n",
    "The reason we don't want sentences that are too long is because the computation becomes trickier for longer sentences and the performance also degrades. However we also want as many sentences in our dataset as possible.\n",
    "\n",
    "Thus it is important to choose the right length and discard sentences longer than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same for the lengths of the output sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 2869  # Number of samples to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [(line[0]) for line in line1]\n",
    "target_texts = [(line[1]) for line in line1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_text in input_texts:\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "\n",
    "for target_text in target_texts:\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "print (len(input_characters))\n",
    "print (len(target_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 2857\n",
      "Number of unique input tokens: 73\n",
      "Number of unique output tokens: 92\n",
      "Max sequence length for inputs: 74\n",
      "Max sequence length for outputs: 82\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            \n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - loss: 1.4797 - val_loss: 2.0893\n",
      "Epoch 2/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - loss: 1.2740 - val_loss: 2.0656\n",
      "Epoch 3/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 188ms/step - loss: 1.2605 - val_loss: 2.0621\n",
      "Epoch 4/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.2551 - val_loss: 2.0578\n",
      "Epoch 5/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - loss: 1.2490 - val_loss: 2.0663\n",
      "Epoch 6/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 218ms/step - loss: 1.2552 - val_loss: 2.0484\n",
      "Epoch 7/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 212ms/step - loss: 1.2515 - val_loss: 2.0269\n",
      "Epoch 8/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 203ms/step - loss: 1.2611 - val_loss: 2.0476\n",
      "Epoch 9/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 214ms/step - loss: 1.2408 - val_loss: 2.0417\n",
      "Epoch 10/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 208ms/step - loss: 1.2319 - val_loss: 2.0411\n",
      "Epoch 11/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.2343 - val_loss: 2.0319\n",
      "Epoch 12/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.2241 - val_loss: 2.0270\n",
      "Epoch 13/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 1.2185 - val_loss: 2.0198\n",
      "Epoch 14/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - loss: 1.2180 - val_loss: 2.0256\n",
      "Epoch 15/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.2276 - val_loss: 2.0212\n",
      "Epoch 16/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - loss: 1.2142 - val_loss: 2.0156\n",
      "Epoch 17/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - loss: 1.2179 - val_loss: 2.0062\n",
      "Epoch 18/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 203ms/step - loss: 1.2178 - val_loss: 2.0165\n",
      "Epoch 19/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - loss: 1.2317 - val_loss: 2.0174\n",
      "Epoch 20/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - loss: 1.2034 - val_loss: 2.0177\n",
      "Epoch 21/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - loss: 1.2247 - val_loss: 2.0041\n",
      "Epoch 22/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 1.2143 - val_loss: 2.0189\n",
      "Epoch 23/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 1.2020 - val_loss: 1.9919\n",
      "Epoch 24/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 1.2091 - val_loss: 1.9904\n",
      "Epoch 25/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - loss: 1.1911 - val_loss: 1.9806\n",
      "Epoch 26/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.1950 - val_loss: 1.9856\n",
      "Epoch 27/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 198ms/step - loss: 1.2083 - val_loss: 2.0179\n",
      "Epoch 28/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.2039 - val_loss: 1.9836\n",
      "Epoch 29/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.1988 - val_loss: 1.9845\n",
      "Epoch 30/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 195ms/step - loss: 1.1873 - val_loss: 1.9738\n",
      "Epoch 31/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 1.1851 - val_loss: 2.0070\n",
      "Epoch 32/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 1.1929 - val_loss: 1.9840\n",
      "Epoch 33/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.1827 - val_loss: 1.9724\n",
      "Epoch 34/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - loss: 1.1927 - val_loss: 1.9771\n",
      "Epoch 35/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 1.1762 - val_loss: 1.9677\n",
      "Epoch 36/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.1814 - val_loss: 1.9625\n",
      "Epoch 37/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 188ms/step - loss: 1.1737 - val_loss: 1.9619\n",
      "Epoch 38/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.1605 - val_loss: 1.9950\n",
      "Epoch 39/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 188ms/step - loss: 1.1732 - val_loss: 1.9739\n",
      "Epoch 40/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - loss: 1.1637 - val_loss: 1.8932\n",
      "Epoch 41/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 1.1611 - val_loss: 1.9674\n",
      "Epoch 42/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - loss: 1.1484 - val_loss: 1.9582\n",
      "Epoch 43/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 1.1600 - val_loss: 1.9140\n",
      "Epoch 44/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 1.1576 - val_loss: 1.9795\n",
      "Epoch 45/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - loss: 1.1455 - val_loss: 1.9630\n",
      "Epoch 46/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.1586 - val_loss: 1.9263\n",
      "Epoch 47/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 207ms/step - loss: 1.1447 - val_loss: 1.9609\n",
      "Epoch 48/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 1.1410 - val_loss: 1.9569\n",
      "Epoch 49/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - loss: 1.1354 - val_loss: 1.9503\n",
      "Epoch 50/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 195ms/step - loss: 1.1288 - val_loss: 1.9066\n",
      "Epoch 51/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 1.1356 - val_loss: 1.9154\n",
      "Epoch 52/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 1.1217 - val_loss: 1.9296\n",
      "Epoch 53/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 190ms/step - loss: 1.1237 - val_loss: 1.8754\n",
      "Epoch 54/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - loss: 1.1088 - val_loss: 1.9552\n",
      "Epoch 55/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 191ms/step - loss: 1.1202 - val_loss: 1.8797\n",
      "Epoch 56/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - loss: 1.1042 - val_loss: 1.9078\n",
      "Epoch 57/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.1220 - val_loss: 1.9485\n",
      "Epoch 58/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 203ms/step - loss: 1.1138 - val_loss: 1.8444\n",
      "Epoch 59/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 1.0899 - val_loss: 1.8497\n",
      "Epoch 60/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 198ms/step - loss: 1.0838 - val_loss: 1.7816\n",
      "Epoch 61/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - loss: 1.0879 - val_loss: 1.9414\n",
      "Epoch 62/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - loss: 1.0853 - val_loss: 1.9077\n",
      "Epoch 63/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - loss: 1.0761 - val_loss: 1.8166\n",
      "Epoch 64/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - loss: 1.0929 - val_loss: 1.8351\n",
      "Epoch 65/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 203ms/step - loss: 1.0782 - val_loss: 1.8415\n",
      "Epoch 66/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 1.0806 - val_loss: 1.8819\n",
      "Epoch 67/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - loss: 1.0696 - val_loss: 1.7801\n",
      "Epoch 68/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step - loss: 1.0423 - val_loss: 1.7669\n",
      "Epoch 69/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 205ms/step - loss: 1.0612 - val_loss: 1.7594\n",
      "Epoch 70/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 198ms/step - loss: 1.0540 - val_loss: 1.8743\n",
      "Epoch 71/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.0328 - val_loss: 1.8816\n",
      "Epoch 72/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - loss: 1.0792 - val_loss: 1.8401\n",
      "Epoch 73/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 199ms/step - loss: 1.0521 - val_loss: 1.8432\n",
      "Epoch 74/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 204ms/step - loss: 1.0338 - val_loss: 1.8052\n",
      "Epoch 75/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 201ms/step - loss: 1.0331 - val_loss: 1.7504\n",
      "Epoch 76/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - loss: 1.0427 - val_loss: 1.7712\n",
      "Epoch 77/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 206ms/step - loss: 1.0320 - val_loss: 1.7030\n",
      "Epoch 78/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 1.0259 - val_loss: 1.8255\n",
      "Epoch 79/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 1.0203 - val_loss: 1.8068\n",
      "Epoch 80/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 1.0157 - val_loss: 1.8466\n",
      "Epoch 81/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - loss: 1.0181 - val_loss: 1.7434\n",
      "Epoch 82/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.0163 - val_loss: 1.7837\n",
      "Epoch 83/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 195ms/step - loss: 1.0060 - val_loss: 1.6710\n",
      "Epoch 84/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - loss: 1.0232 - val_loss: 1.8142\n",
      "Epoch 85/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 0.9974 - val_loss: 1.6947\n",
      "Epoch 86/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - loss: 1.0012 - val_loss: 1.6992\n",
      "Epoch 87/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 198ms/step - loss: 0.9950 - val_loss: 1.7358\n",
      "Epoch 88/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.0053 - val_loss: 1.8359\n",
      "Epoch 89/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.0373 - val_loss: 1.7728\n",
      "Epoch 90/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 0.9857 - val_loss: 1.6885\n",
      "Epoch 91/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 189ms/step - loss: 0.9841 - val_loss: 1.7467\n",
      "Epoch 92/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 1.0035 - val_loss: 1.6956\n",
      "Epoch 93/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 0.9965 - val_loss: 1.7180\n",
      "Epoch 94/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 196ms/step - loss: 0.9851 - val_loss: 1.6997\n",
      "Epoch 95/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - loss: 0.9827 - val_loss: 1.7026\n",
      "Epoch 96/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 194ms/step - loss: 0.9779 - val_loss: 1.7581\n",
      "Epoch 97/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 0.9819 - val_loss: 1.8031\n",
      "Epoch 98/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 190ms/step - loss: 1.0128 - val_loss: 1.7437\n",
      "Epoch 99/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - loss: 0.9810 - val_loss: 1.7285\n",
      "Epoch 100/100\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 192ms/step - loss: 0.9650 - val_loss: 1.6733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f5e79a5510>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('s2s.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Exception encountered when calling Functional.call().\\n\\n\\x1b[1m2155881738256\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=('tf.Tensor(shape=(1, 1, 92), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)')\\n  • training=False\\n  • mask=('None', 'None', 'None')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m      3\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m encoder_input_data[seq_index: seq_index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m     decoded_sentence \u001b[38;5;241m=\u001b[39m decode_sequence(input_seq)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(input_texts[seq_index])\n",
      "Cell \u001b[1;32mIn[37], line 10\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      8\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_condition:\n\u001b[1;32m---> 10\u001b[0m     output_tokens, h, c \u001b[38;5;241m=\u001b[39m decoder_model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     11\u001b[0m         [target_seq] \u001b[38;5;241m+\u001b[39m states_value)\n\u001b[0;32m     13\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     14\u001b[0m     sampled_char \u001b[38;5;241m=\u001b[39m reverse_target_char_index[sampled_token_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\ops\\function.py:159\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[1;34m(self, inputs, operation_fn)\u001b[0m\n\u001b[0;32m    157\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m--> 159\u001b[0m     output_tensors\u001b[38;5;241m.\u001b[39mappend(tensor_dict[\u001b[38;5;28mid\u001b[39m(x)])\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mpack_sequence_as(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_struct, output_tensors)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Exception encountered when calling Functional.call().\\n\\n\\x1b[1m2155881738256\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=('tf.Tensor(shape=(1, 1, 92), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)')\\n  • training=False\\n  • mask=('None', 'None', 'None')\""
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print(input_texts[seq_index])\n",
    "    print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"You are not subscribed to this API.\"}\n"
     ]
    }
   ],
   "source": [
    "import http.client\n",
    "\n",
    "conn = http.client.HTTPSConnection(\"google-translate113.p.rapidapi.com\")\n",
    "\n",
    "payload = \"from=auto&to=en&text=xin%20ch%C3%A0o\"\n",
    "\n",
    "headers = {\n",
    "    'content-type': \"application/x-www-form-urlencoded\",\n",
    "    'X-RapidAPI-Key': \"SIGN-UP-FOR-KEY\",\n",
    "    'X-RapidAPI-Host': \"google-translate113.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "conn.request(\"POST\", \"/api/v1/translator/text\", payload, headers)\n",
    "\n",
    "res = conn.getresponse()\n",
    "data = res.read()\n",
    "\n",
    "print(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Exception encountered when calling Functional.call().\\n\\n\\x1b[1m2155881738256\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=('tf.Tensor(shape=(1, 1, 92), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)')\\n  • training=False\\n  • mask=('None', 'None', 'None')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m         input_sequence[\u001b[38;5;241m0\u001b[39m, t, input_token_index[char]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Decode the input sequence and print the translated sentence\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m translated_sentence \u001b[38;5;241m=\u001b[39m decode_sequence(input_sequence)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated Sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, translated_sentence)\n",
      "Cell \u001b[1;32mIn[32], line 28\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     26\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_condition:\n\u001b[1;32m---> 28\u001b[0m     output_tokens, h, c \u001b[38;5;241m=\u001b[39m decoder_model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     29\u001b[0m         [target_seq] \u001b[38;5;241m+\u001b[39m states_value)\n\u001b[0;32m     31\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     32\u001b[0m     sampled_char \u001b[38;5;241m=\u001b[39m reverse_target_char_index[sampled_token_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\ops\\function.py:159\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[1;34m(self, inputs, operation_fn)\u001b[0m\n\u001b[0;32m    157\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m--> 159\u001b[0m     output_tensors\u001b[38;5;241m.\u001b[39mappend(tensor_dict[\u001b[38;5;28mid\u001b[39m(x)])\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mpack_sequence_as(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_struct, output_tensors)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Exception encountered when calling Functional.call().\\n\\n\\x1b[1m2155881738256\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=('tf.Tensor(shape=(1, 1, 92), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)')\\n  • training=False\\n  • mask=('None', 'None', 'None')\""
     ]
    }
   ],
   "source": [
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    input_sentence = input(\"Enter a sentence to translate (type 'quit' to exit): \")\n",
    "\n",
    "    # Check if the user wants to quit\n",
    "    if input_sentence.lower() == 'quit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Encode the input sentence\n",
    "    input_sequence = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    for t, char in enumerate(input_sentence):\n",
    "        if char in input_token_index:\n",
    "            input_sequence[0, t, input_token_index[char]] = 1.\n",
    "\n",
    "    # Decode the input sequence and print the translated sentence\n",
    "    translated_sentence = decode_sequence(input_sequence)\n",
    "    print(\"Translated Sentence:\", translated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Exception encountered when calling Functional.call().\\n\\n\\x1b[1m2155881738256\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=('tf.Tensor(shape=(1, 1, 92), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)')\\n  • training=False\\n  • mask=('None', 'None', 'None')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Translate the input sentence to Hindi\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m translated_sentence \u001b[38;5;241m=\u001b[39m translate_to_hindi(input_sentence)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Print the translated sentence\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated Sentence (Hindi):\u001b[39m\u001b[38;5;124m\"\u001b[39m, translated_sentence)\n",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m, in \u001b[0;36mtranslate_to_hindi\u001b[1;34m(input_sentence)\u001b[0m\n\u001b[0;32m      7\u001b[0m         input_sequence[\u001b[38;5;241m0\u001b[39m, t, input_token_index[char]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Decode the input sequence and get the translated sentence\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m translated_sentence \u001b[38;5;241m=\u001b[39m decode_sequence(input_sequence)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m translated_sentence\n",
      "Cell \u001b[1;32mIn[32], line 28\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     26\u001b[0m decoded_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_condition:\n\u001b[1;32m---> 28\u001b[0m     output_tokens, h, c \u001b[38;5;241m=\u001b[39m decoder_model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m     29\u001b[0m         [target_seq] \u001b[38;5;241m+\u001b[39m states_value)\n\u001b[0;32m     31\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     32\u001b[0m     sampled_char \u001b[38;5;241m=\u001b[39m reverse_target_char_index[sampled_token_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\ops\\function.py:159\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[1;34m(self, inputs, operation_fn)\u001b[0m\n\u001b[0;32m    157\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m--> 159\u001b[0m     output_tensors\u001b[38;5;241m.\u001b[39mappend(tensor_dict[\u001b[38;5;28mid\u001b[39m(x)])\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mpack_sequence_as(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_struct, output_tensors)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Exception encountered when calling Functional.call().\\n\\n\\x1b[1m2155881738256\\x1b[0m\\n\\nArguments received by Functional.call():\\n  • inputs=('tf.Tensor(shape=(1, 1, 92), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)', 'tf.Tensor(shape=(1, 256), dtype=float32)')\\n  • training=False\\n  • mask=('None', 'None', 'None')\""
     ]
    }
   ],
   "source": [
    "# Function to translate English sentences to Hindi\n",
    "def translate_to_hindi(input_sentence):\n",
    "    # Encode the input sentence\n",
    "    input_sequence = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    for t, char in enumerate(input_sentence):\n",
    "        if char in input_token_index:\n",
    "            input_sequence[0, t, input_token_index[char]] = 1.\n",
    "    \n",
    "    # Decode the input sequence and get the translated sentence\n",
    "    translated_sentence = decode_sequence(input_sequence)\n",
    "    \n",
    "    return translated_sentence\n",
    "\n",
    "# Get user input and translate to Hindi\n",
    "while True:\n",
    "    # Get user input\n",
    "    input_sentence = input(\"Enter an English sentence to translate (type 'quit' to exit): \")\n",
    "    \n",
    "    # Check if the user wants to quit\n",
    "    if input_sentence.lower() == 'quit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Translate the input sentence to Hindi\n",
    "    translated_sentence = translate_to_hindi(input_sentence)\n",
    "    \n",
    "    # Print the translated sentence\n",
    "    print(\"Translated Sentence (Hindi):\", translated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m target_language \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter the target language (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for English, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for Hindi): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Translate the input text\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m translated_text \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_language\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_language\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Display the translated text\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranslated text:\u001b[39m\u001b[38;5;124m\"\u001b[39m, translated_text)\n",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m, in \u001b[0;36mtranslate_text\u001b[1;34m(text, target_language)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mTranslates the given text to the specified target language.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    str: Translated text.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize the translation client\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Translate the text\u001b[39;00m\n\u001b[0;32m     18\u001b[0m translation \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mtranslate(text, target_language\u001b[38;5;241m=\u001b[39mtarget_language)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\translate_v2\\client.py:79\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, target_language, credentials, _http, client_info, client_options)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     72\u001b[0m     target_language\u001b[38;5;241m=\u001b[39mENGLISH_ISO_639,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m     client_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m ):\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_language \u001b[38;5;241m=\u001b[39m target_language\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_http\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_http\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     kw_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: client_info}\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m client_options:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\client\\__init__.py:178\u001b[0m, in \u001b[0;36mClient.__init__\u001b[1;34m(self, credentials, _http, client_options)\u001b[0m\n\u001b[0;32m    174\u001b[0m         credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[0;32m    175\u001b[0m             client_options\u001b[38;5;241m.\u001b[39mcredentials_file, scopes\u001b[38;5;241m=\u001b[39mscopes\n\u001b[0;32m    176\u001b[0m         )\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m         credentials, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mcredentials\u001b[38;5;241m.\u001b[39mwith_scopes_if_required(\n\u001b[0;32m    181\u001b[0m     credentials, scopes\u001b[38;5;241m=\u001b[39mscopes\n\u001b[0;32m    182\u001b[0m )\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client_options\u001b[38;5;241m.\u001b[39mquota_project_id:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\auth\\_default.py:691\u001b[0m, in \u001b[0;36mdefault\u001b[1;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[0;32m    683\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    684\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    685\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[0;32m    688\u001b[0m             )\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[1;32m--> 691\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[1;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "\n",
    "from google.cloud import translate_v2 as translate\n",
    "\n",
    "def translate_text(text, target_language='en'):\n",
    "    \"\"\"\n",
    "    Translates the given text to the specified target language.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to be translated.\n",
    "        target_language (str): The target language code (e.g., 'en' for English, 'hi' for Hindi).\n",
    "    \n",
    "    Returns:\n",
    "        str: Translated text.\n",
    "    \"\"\"\n",
    "    # Initialize the translation client\n",
    "    client = translate.Client()\n",
    "\n",
    "    # Translate the text\n",
    "    translation = client.translate(text, target_language=target_language)\n",
    "\n",
    "    return translation['translatedText']\n",
    "\n",
    "# Prompt the user to input text\n",
    "input_text = input(\"Enter the text to be translated: \")\n",
    "\n",
    "# Ask the user for the target language\n",
    "target_language = input(\"Enter the target language ('en' for English, 'hi' for Hindi): \")\n",
    "\n",
    "# Translate the input text\n",
    "translated_text = translate_text(input_text, target_language=target_language)\n",
    "\n",
    "# Display the translated text\n",
    "print(\"Translated text:\", translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated text: None\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def translate_text(text, target_language='en'):\n",
    "    \"\"\"\n",
    "    Translates the given text to the specified target language using the Google Translate API via RapidAPI.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be translated.\n",
    "        target_language (str): The target language code (e.g., 'en' for English, 'hi' for Hindi).\n",
    "\n",
    "    Returns:\n",
    "        str: Translated text.\n",
    "    \"\"\"\n",
    "    url = \"https://google-translate113.p.rapidapi.com/api/v1/translator/text\"\n",
    "    headers = {\n",
    "        \"content-type\": \"application/x-www-form-urlencoded\",\n",
    "        \"X-RapidAPI-Key\": \"88cbbe7183mshd74b505065ae9bbp116d8ejsn6f397dab0add\",\n",
    "        \"X-RapidAPI-Host\": \"google-translate113.p.rapidapi.com\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"from\": \"auto\",\n",
    "        \"to\": target_language,\n",
    "        \"text\": text\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, data=payload, headers=headers)\n",
    "    translated_text = response.json().get('data', {}).get('translation')\n",
    "\n",
    "    return translated_text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"Bonjour\"\n",
    "target_language = \"en\"\n",
    "translated_text = translate_text(input_text, target_language)\n",
    "print(\"Translated text:\", translated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
